#!/bin/bash

# --- 1. ç¯å¢ƒæ¸…ç† ---
echo "æ­£åœ¨æ¸…ç†æ—§ç¯å¢ƒ..."
cd /root/manga_bot 2>/dev/null
docker-compose down --rmi all 2>/dev/null
pkill -f bot_writer.py 2>/dev/null
pkill -f auto_scraper.py 2>/dev/null

# --- 2. å…¨äº¤äº’é…ç½® ---
echo "--- æ¼«ç”»ä¸‹è½½æœºå™¨äºº å…¨äº¤äº’éƒ¨ç½²è„šæœ¬ ---"

# äº¤äº’è¾“å…¥ Token
READ_TOKEN=""
while [ -z "$READ_TOKEN" ]; do
    read -p "è¯·è¾“å…¥ä½ çš„ Telegram Bot Token: " READ_TOKEN
done

# äº¤äº’è¾“å…¥ User ID
READ_ID=""
while [ -z "$READ_ID" ]; do
    read -p "è¯·è¾“å…¥ä½ çš„ Telegram User ID: " READ_ID
done

# äº¤äº’è¾“å…¥ä¸‹è½½è·¯å¾„ (æä¾›é»˜è®¤å€¼)
DEFAULT_DIR="/root/docker/manhua/comics"
read -p "è¯·è¾“å…¥ä¸‹è½½ä¿å­˜è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ $DEFAULT_DIR): " READ_DIR
DOWNLOAD_DIR=${READ_DIR:-$DEFAULT_DIR}

PROJECT_DIR="/root/manga_bot"

echo "æ­£åœ¨å‡†å¤‡ç›®å½•..."
mkdir -p $PROJECT_DIR
mkdir -p $DOWNLOAD_DIR
cd $PROJECT_DIR

# --- 3. æœºå™¨äººè„šæœ¬ (bot_writer.py) ---
cat <<EOF > bot_writer.py
import os, asyncio
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes

TOKEN = "$READ_TOKEN"
MY_ID = $READ_ID
WEB_TXT_PATH = "web.txt"
FINISH_TXT = "finish.txt"
# è¿™é‡Œçš„è·¯å¾„ä¼šæ ¹æ®ä½ è¾“å…¥çš„å†…å®¹åŠ¨æ€ç”Ÿæˆ
DISPLAY_PATH = "$DOWNLOAD_DIR"

async def handle_link(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id != MY_ID: return
    url = update.message.text.strip()
    if url.startswith("http"):
        with open(WEB_TXT_PATH, "a", encoding="utf-8") as f:
            f.write(f"{url}\n")
        await update.message.reply_text("âœ… ä»»åŠ¡å·²æ’é˜Ÿï¼Œå®Œæˆåæˆ‘ä¼šé€šçŸ¥ã€‚")

async def check_finish(context: ContextTypes.DEFAULT_TYPE):
    if os.path.exists(FINISH_TXT) and os.path.getsize(FINISH_TXT) > 0:
        with open(FINISH_TXT, "r", encoding="utf-8") as f:
            titles = f.readlines()
        open(FINISH_TXT, "w").close()
        for title in titles:
            t = title.strip()
            if t:
                msg = f"ğŸ ä¸‹è½½æˆåŠŸï¼\n\nã€{t}ã€‘\n\nğŸ“‚ å­˜æ¡£ä½ç½®ï¼š\n{DISPLAY_PATH}/{t}.cbz"
                await context.bot.send_message(chat_id=MY_ID, text=msg)

if __name__ == "__main__":
    app = Application.builder().token(TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_link))
    if app.job_queue:
        app.job_queue.run_repeating(check_finish, interval=30, first=10)
    print("ğŸ¤– æœºå™¨äººå·²å¯åŠ¨...")
    app.run_polling()
EOF

# --- 4. çˆ¬è™«è„šæœ¬ (auto_scraper.py) ---
cat <<EOF > auto_scraper.py
import os, shutil, requests, random, time, zipfile, urllib3, io
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from PIL import Image
from concurrent.futures import ThreadPoolExecutor, as_completed

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

WEB_TXT_PATH = "web.txt"
FINISH_TXT = "finish.txt"
DEST_DIR = "/downloads"

def down_img(url, idx, temp_dir):
    try:
        h = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=h, timeout=15, verify=False)
        if r.status_code != 200: return None
        jpg_path = os.path.join(temp_dir, f"{idx:03d}.jpg")
        with Image.open(io.BytesIO(r.content)) as im:
            im.convert('RGB').save(jpg_path, 'JPEG', quality=95)
        return jpg_path
    except: return None

def process_url(url):
    tid = int(time.time())
    tmp_d = f"tmp_{tid}"
    os.makedirs(tmp_d, exist_ok=True)
    try:
        h = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=h, timeout=15, verify=False)
        r.encoding = r.apparent_encoding
        soup = BeautifulSoup(r.text, 'html.parser')
        title = (soup.title.string if soup.title else f"manga_{tid}").strip()
        for c in '/\\\\:*?"<>| ': title = title.replace(c, '_')
        
        img_urls = []
        for img in soup.find_all('img'):
            src = img.get('data-original') or img.get('data-src') or img.get('src')
            if src and not src.startswith('data:'): img_urls.append(urljoin(url, src))
        img_urls = list(dict.fromkeys(img_urls))

        if not img_urls: return False

        print(f"\nğŸš€ å¼€å§‹å¤„ç†: {title}")
        jpgs = []
        with ThreadPoolExecutor(max_workers=10) as exe:
            futures = [exe.submit(down_img, u, i, tmp_d) for i, u in enumerate(img_urls)]
            count = 0
            for f in as_completed(futures):
                count += 1
                if f.result(): jpgs.append(f.result())
                if count % 5 == 0 or count == len(img_urls):
                    print(f"   è¿›åº¦: [{count}/{len(img_urls)}]")

        if jpgs:
            cbz = f"{title}.cbz"
            with zipfile.ZipFile(cbz, 'w') as z:
                for f in sorted(jpgs): z.write(f, os.path.basename(f))
            shutil.move(cbz, os.path.join(DEST_DIR, cbz))
            with open(FINISH_TXT, "a", encoding="utf-8") as f:
                f.write(f"{title}\n")
            print(f"âœ… å®Œæˆ: {cbz}")
            return True
        return False
    except Exception as e:
        print(f"ğŸ’¥ å¼‚å¸¸: {e}")
        return False
    finally:
        if os.path.exists(tmp_d): shutil.rmtree(tmp_d)

def main():
    while True:
        if not os.path.exists(WEB_TXT_PATH) or os.path.getsize(WEB_TXT_PATH) == 0:
            time.sleep(10); continue
        with open(WEB_TXT_PATH, 'r', encoding='utf-8') as f: lines = f.readlines()
        url = lines[0].strip()
        if url: process_url(url)
        with open(WEB_TXT_PATH, 'w', encoding='utf-8') as f: f.writelines(lines[1:])

if __name__ == "__main__":
    main()
EOF

# --- 5. Docker é…ç½® ---
echo "python-telegram-bot[job-queue]" > requirements.txt
echo "requests" >> requirements.txt
echo "beautifulsoup4" >> requirements.txt
echo "Pillow" >> requirements.txt

cat <<EOF > Dockerfile
FROM python:3.10-slim
RUN apt-get update && apt-get install -y libjpeg-dev zlib1g-dev && rm -rf /var/lib/apt/lists/*
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["sh", "-c", "python3 bot_writer.py & python3 auto_scraper.py"]
EOF

cat <<EOF > docker-compose.yml
version: '3.8'
services:
  manga-bot:
    build: .
    container_name: manga_bot_container
    restart: always
    volumes:
      - $DOWNLOAD_DIR:/downloads
      - .:/app
    environment:
      - TZ=Asia/Shanghai
      - PYTHONUNBUFFERED=1
EOF

# --- 6. å¯åŠ¨ ---
touch web.txt finish.txt
docker-compose up -d --build

echo "------------------------------------------------"
echo "âœ¨ éƒ¨ç½²æˆåŠŸï¼"
echo "ğŸ“‚ ä¿å­˜ç›®å½•ï¼š$DOWNLOAD_DIR"
echo "ğŸ“Š å®æ—¶æ—¥å¿—ï¼šdocker logs -f manga_bot_container"
echo "------------------------------------------------"
